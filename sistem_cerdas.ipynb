{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tahap 1: Membangun Database (Balanced Contrast) ---\n",
      "Memproses kategori: angry...\n",
      "Memproses kategori: disgust...\n",
      "Memproses kategori: fear...\n",
      "Memproses kategori: happy...\n",
      "Memproses kategori: sad...\n",
      "Memproses kategori: surprise...\n",
      "Memproses kategori: neutral...\n",
      "\n",
      "========================================\n",
      "STATISTIK DATABASE BERHASIL DIBUAT\n",
      "========================================\n",
      "angry          : 3995 gambar\n",
      "disgust        : 436 gambar\n",
      "fear           : 4097 gambar\n",
      "happy          : 7215 gambar\n",
      "sad            : 4830 gambar\n",
      "surprise       : 3171 gambar\n",
      "neutral        : 4965 gambar\n",
      "----------------------------------------\n",
      "Total Data Berhasil : 28709\n",
      "Total Data Gagal    : 0\n",
      "========================================\n",
      "SUKSES! File 'database_emosi.csv' siap digunakan.\n",
      "Silakan lanjut ke Cell 2 (Training).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 1. Konfigurasi Folder\n",
    "train_path = 'dataset/train' \n",
    "emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "\n",
    "data_list = []\n",
    "summary = {label: 0 for label in emotion_labels} # Menghitung statistik tiap emosi\n",
    "failed_files = []\n",
    "\n",
    "# --- Inisialisasi CLAHE ---\n",
    "# Memperjelas fitur wajah (mata/mulut) tanpa menciptakan noise berlebih\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "print(\"--- Tahap 1: Membangun Database (Balanced Contrast) ---\")\n",
    "\n",
    "# 2. Iterasi Folder Emosi\n",
    "for label_idx, emotion in enumerate(emotion_labels):\n",
    "    folder_path = os.path.join(train_path, emotion)\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Peringatan: Folder '{emotion}' tidak ditemukan, melewati...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Memproses kategori: {emotion}...\")\n",
    "    \n",
    "    for img_name in os.listdir(folder_path):\n",
    "        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            \n",
    "            try:\n",
    "                # Membaca gambar dalam mode Grayscale\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                # --- CLAHE (Adaptive Equalization) ---\n",
    "                img = clahe.apply(img)\n",
    "                \n",
    "                # Resize ke standar model 48x48 piksel\n",
    "                img = cv2.resize(img, (48, 48))\n",
    "                \n",
    "                # Mengonversi matriks menjadi string piksel (flatten)\n",
    "                pixel_string = \" \".join(img.flatten().astype(str))\n",
    "                \n",
    "                data_list.append([label_idx, pixel_string])\n",
    "                summary[emotion] += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                failed_files.append(f\"{img_name}: {str(e)}\")\n",
    "\n",
    "# 3. Konversi ke DataFrame & SHUFFLE\n",
    "# Mengacak urutan data agar distribusi emosi merata di dalam CSV\n",
    "df = pd.DataFrame(data_list, columns=['emotion', 'pixels'])\n",
    "df = shuffle(df).reset_index(drop=True) \n",
    "\n",
    "# 4. Simpan ke CSV\n",
    "df.to_csv('database_emosi.csv', index=False)\n",
    "\n",
    "# 5. Laporan Statistik\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"STATISTIK DATABASE BERHASIL DIBUAT\")\n",
    "print(\"=\"*40)\n",
    "for emosi, jumlah in summary.items():\n",
    "    print(f\"{emosi.ljust(15)}: {jumlah} gambar\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Total Data Berhasil : {len(df)}\")\n",
    "print(f\"Total Data Gagal    : {len(failed_files)}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "if len(df) > 0:\n",
    "    print(\"SUKSES! File 'database_emosi.csv' siap digunakan.\")\n",
    "    print(\"Silakan lanjut ke Cell 2 (Training).\")\n",
    "else:\n",
    "    print(\"EROR: Tidak ada data yang berhasil dikonversi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tahap 1: Memuat Pengetahuan (Database) ---\n",
      "Berhasil memuat 28709 data pengalaman.\n",
      "Distribusi Emosi dalam Database:\n",
      "emotion\n",
      "0    3995\n",
      "1     436\n",
      "2    4097\n",
      "3    7215\n",
      "4    4830\n",
      "5    3171\n",
      "6    4965\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Tahap 2: Preprocessing ---\n",
      "Bobot emosi telah dimodifikasi.\n",
      "\n",
      "--- Tahap 3: Membangun Otak Buatan (Deep Architecture) ---\n",
      "Arsitektur JST Berhasil dibentuk.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,720,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m4,720,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,492,103</span> (28.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,492,103\u001b[0m (28.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,484,423</span> (28.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,484,423\u001b[0m (28.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> (30.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,680\u001b[0m (30.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tahap 4: Proses Belajar (Deep Learning) ---\n",
      "Epoch 1/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 95ms/step - accuracy: 0.2650 - loss: 2.7360 - val_accuracy: 0.3332 - val_loss: 1.7411 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 85ms/step - accuracy: 0.3274 - loss: 2.3151 - val_accuracy: 0.3400 - val_loss: 1.7656 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 85ms/step - accuracy: 0.3533 - loss: 2.1951 - val_accuracy: 0.3187 - val_loss: 1.7190 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 84ms/step - accuracy: 0.3654 - loss: 2.0991 - val_accuracy: 0.3386 - val_loss: 1.7212 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 83ms/step - accuracy: 0.3770 - loss: 2.0525 - val_accuracy: 0.3339 - val_loss: 1.7467 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 83ms/step - accuracy: 0.3935 - loss: 1.9801 - val_accuracy: 0.2682 - val_loss: 1.9970 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 84ms/step - accuracy: 0.3981 - loss: 1.9576 - val_accuracy: 0.3386 - val_loss: 1.8371 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.4067 - loss: 1.9053 - val_accuracy: 0.3039 - val_loss: 1.8342 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - accuracy: 0.4128 - loss: 1.8728 - val_accuracy: 0.3170 - val_loss: 1.7329 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.4294 - loss: 1.8119\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - accuracy: 0.4223 - loss: 1.8332 - val_accuracy: 0.3440 - val_loss: 1.7644 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 95ms/step - accuracy: 0.4469 - loss: 1.7108 - val_accuracy: 0.3917 - val_loss: 1.6387 - learning_rate: 2.5000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 89ms/step - accuracy: 0.4627 - loss: 1.6529 - val_accuracy: 0.3812 - val_loss: 1.7159 - learning_rate: 2.5000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.4764 - loss: 1.6172 - val_accuracy: 0.4030 - val_loss: 1.5775 - learning_rate: 2.5000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.4804 - loss: 1.5878 - val_accuracy: 0.3858 - val_loss: 1.5936 - learning_rate: 2.5000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.4866 - loss: 1.5620 - val_accuracy: 0.3696 - val_loss: 1.7544 - learning_rate: 2.5000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.4928 - loss: 1.5475 - val_accuracy: 0.3736 - val_loss: 1.8483 - learning_rate: 2.5000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.4975 - loss: 1.5216 - val_accuracy: 0.3389 - val_loss: 1.7833 - learning_rate: 2.5000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.5047 - loss: 1.5094 - val_accuracy: 0.3889 - val_loss: 1.6882 - learning_rate: 2.5000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.4974 - loss: 1.5220 - val_accuracy: 0.3903 - val_loss: 1.7535 - learning_rate: 2.5000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5078 - loss: 1.4947\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.5079 - loss: 1.5135 - val_accuracy: 0.3974 - val_loss: 1.6180 - learning_rate: 2.5000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.5150 - loss: 1.4605 - val_accuracy: 0.4295 - val_loss: 1.5639 - learning_rate: 1.2500e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.5258 - loss: 1.4163 - val_accuracy: 0.4080 - val_loss: 1.6194 - learning_rate: 1.2500e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.5349 - loss: 1.3921 - val_accuracy: 0.4178 - val_loss: 1.6564 - learning_rate: 1.2500e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.5384 - loss: 1.3819 - val_accuracy: 0.4272 - val_loss: 1.5930 - learning_rate: 1.2500e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 85ms/step - accuracy: 0.5447 - loss: 1.3621 - val_accuracy: 0.4227 - val_loss: 1.6201 - learning_rate: 1.2500e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.5470 - loss: 1.3559 - val_accuracy: 0.4267 - val_loss: 1.6540 - learning_rate: 1.2500e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 93ms/step - accuracy: 0.5552 - loss: 1.3326 - val_accuracy: 0.4171 - val_loss: 1.6532 - learning_rate: 1.2500e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5521 - loss: 1.3333\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 85ms/step - accuracy: 0.5534 - loss: 1.3281 - val_accuracy: 0.4270 - val_loss: 1.6668 - learning_rate: 1.2500e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.5676 - loss: 1.2847 - val_accuracy: 0.4382 - val_loss: 1.6164 - learning_rate: 6.2500e-05\n",
      "Epoch 30/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.5721 - loss: 1.2693 - val_accuracy: 0.4361 - val_loss: 1.6154 - learning_rate: 6.2500e-05\n",
      "Epoch 31/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - accuracy: 0.5775 - loss: 1.2550 - val_accuracy: 0.4427 - val_loss: 1.6119 - learning_rate: 6.2500e-05\n",
      "Epoch 32/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 85ms/step - accuracy: 0.5780 - loss: 1.2517 - val_accuracy: 0.4418 - val_loss: 1.6283 - learning_rate: 6.2500e-05\n",
      "Epoch 33/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.5815 - loss: 1.2404 - val_accuracy: 0.4373 - val_loss: 1.6351 - learning_rate: 6.2500e-05\n",
      "Epoch 34/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.5811 - loss: 1.2368 - val_accuracy: 0.4361 - val_loss: 1.6469 - learning_rate: 6.2500e-05\n",
      "Epoch 35/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5864 - loss: 1.2256\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 88ms/step - accuracy: 0.5885 - loss: 1.2243 - val_accuracy: 0.4354 - val_loss: 1.6254 - learning_rate: 6.2500e-05\n",
      "Epoch 36/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - accuracy: 0.5941 - loss: 1.2020 - val_accuracy: 0.4382 - val_loss: 1.6516 - learning_rate: 3.1250e-05\n",
      "Epoch 37/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 85ms/step - accuracy: 0.5925 - loss: 1.2103 - val_accuracy: 0.4403 - val_loss: 1.6496 - learning_rate: 3.1250e-05\n",
      "Epoch 38/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 85ms/step - accuracy: 0.5971 - loss: 1.1899 - val_accuracy: 0.4380 - val_loss: 1.6207 - learning_rate: 3.1250e-05\n",
      "Epoch 39/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.6005 - loss: 1.1911 - val_accuracy: 0.4444 - val_loss: 1.6413 - learning_rate: 3.1250e-05\n",
      "Epoch 40/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.6003 - loss: 1.1774 - val_accuracy: 0.4418 - val_loss: 1.6673 - learning_rate: 3.1250e-05\n",
      "Epoch 41/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.5958 - loss: 1.1960 - val_accuracy: 0.4417 - val_loss: 1.6582 - learning_rate: 3.1250e-05\n",
      "Epoch 42/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6038 - loss: 1.1679\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - accuracy: 0.6025 - loss: 1.1727 - val_accuracy: 0.4404 - val_loss: 1.6505 - learning_rate: 3.1250e-05\n",
      "Epoch 43/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.6015 - loss: 1.1682 - val_accuracy: 0.4390 - val_loss: 1.6470 - learning_rate: 1.5625e-05\n",
      "Epoch 44/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 84ms/step - accuracy: 0.6041 - loss: 1.1590 - val_accuracy: 0.4436 - val_loss: 1.6564 - learning_rate: 1.5625e-05\n",
      "Epoch 45/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 83ms/step - accuracy: 0.6067 - loss: 1.1711 - val_accuracy: 0.4410 - val_loss: 1.6727 - learning_rate: 1.5625e-05\n",
      "Epoch 46/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 85ms/step - accuracy: 0.6085 - loss: 1.1545 - val_accuracy: 0.4443 - val_loss: 1.6573 - learning_rate: 1.5625e-05\n",
      "Epoch 47/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 84ms/step - accuracy: 0.6127 - loss: 1.1478 - val_accuracy: 0.4397 - val_loss: 1.6645 - learning_rate: 1.5625e-05\n",
      "Epoch 48/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 85ms/step - accuracy: 0.6085 - loss: 1.1472 - val_accuracy: 0.4375 - val_loss: 1.6663 - learning_rate: 1.5625e-05\n",
      "Epoch 49/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6119 - loss: 1.1456\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 85ms/step - accuracy: 0.6115 - loss: 1.1440 - val_accuracy: 0.4399 - val_loss: 1.6684 - learning_rate: 1.5625e-05\n",
      "Epoch 50/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - accuracy: 0.6101 - loss: 1.1471 - val_accuracy: 0.4408 - val_loss: 1.6722 - learning_rate: 1.0000e-05\n",
      "Epoch 51/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 84ms/step - accuracy: 0.6104 - loss: 1.1345 - val_accuracy: 0.4389 - val_loss: 1.6723 - learning_rate: 1.0000e-05\n",
      "Epoch 52/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - accuracy: 0.6123 - loss: 1.1509 - val_accuracy: 0.4383 - val_loss: 1.6694 - learning_rate: 1.0000e-05\n",
      "Epoch 53/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - accuracy: 0.6095 - loss: 1.1470 - val_accuracy: 0.4415 - val_loss: 1.6769 - learning_rate: 1.0000e-05\n",
      "Epoch 54/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.6127 - loss: 1.1470 - val_accuracy: 0.4403 - val_loss: 1.6706 - learning_rate: 1.0000e-05\n",
      "Epoch 55/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.6157 - loss: 1.1289 - val_accuracy: 0.4420 - val_loss: 1.6651 - learning_rate: 1.0000e-05\n",
      "Epoch 56/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.6130 - loss: 1.1402 - val_accuracy: 0.4399 - val_loss: 1.6761 - learning_rate: 1.0000e-05\n",
      "Epoch 57/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.6102 - loss: 1.1440 - val_accuracy: 0.4394 - val_loss: 1.6725 - learning_rate: 1.0000e-05\n",
      "Epoch 58/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.6190 - loss: 1.1226 - val_accuracy: 0.4410 - val_loss: 1.6666 - learning_rate: 1.0000e-05\n",
      "Epoch 59/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.6142 - loss: 1.1355 - val_accuracy: 0.4401 - val_loss: 1.6709 - learning_rate: 1.0000e-05\n",
      "Epoch 60/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 85ms/step - accuracy: 0.6177 - loss: 1.1332 - val_accuracy: 0.4415 - val_loss: 1.6746 - learning_rate: 1.0000e-05\n",
      "Epoch 61/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 90ms/step - accuracy: 0.6164 - loss: 1.1276 - val_accuracy: 0.4408 - val_loss: 1.6731 - learning_rate: 1.0000e-05\n",
      "Epoch 62/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.6134 - loss: 1.1341 - val_accuracy: 0.4434 - val_loss: 1.6792 - learning_rate: 1.0000e-05\n",
      "Epoch 63/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.6144 - loss: 1.1248 - val_accuracy: 0.4399 - val_loss: 1.6734 - learning_rate: 1.0000e-05\n",
      "Epoch 64/150\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.6161 - loss: 1.1308 - val_accuracy: 0.4408 - val_loss: 1.6797 - learning_rate: 1.0000e-05\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "\n",
      "========================================\n",
      "RINGKASAN HASIL TRAINING\n",
      "========================================\n",
      "Akurasi Latihan   : 61.61%\n",
      "Akurasi Validasi  : 44.08%\n",
      "----------------------------------------\n",
      "HASIL ANALISIS:\n",
      "SISTEM BERHASIL.\n",
      "========================================\n",
      "[SUKSES] Model final disimpan sebagai 'model_cerdas.keras'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "\n",
    "# 1. Load Data dari Database CSV\n",
    "print(\"--- Tahap 1: Memuat Pengetahuan (Database) ---\")\n",
    "if os.path.exists('database_emosi.csv'):\n",
    "    df = pd.read_csv('database_emosi.csv')\n",
    "    \n",
    "    # MENGACAK DATA agar tidak kaku\n",
    "    df = shuffle(df).reset_index(drop=True)\n",
    "    print(f\"Berhasil memuat {len(df)} data pengalaman.\")\n",
    "    \n",
    "    print(\"Distribusi Emosi dalam Database:\")\n",
    "    print(df['emotion'].value_counts().sort_index())\n",
    "    # Index: 0:Angry, 1:Disgust, 2:Fear, 3:Happy, 4:Sad, 5:Surprise, 6:Neutral\n",
    "else:\n",
    "    print(\"Error: File 'database_emosi.csv' tidak ditemukan! Silakan jalankan Cell 1 dulu.\")\n",
    "\n",
    "# 2. Preprocessing & Normalisasi\n",
    "print(\"\\n--- Tahap 2: Preprocessing ---\")\n",
    "X = np.array([np.fromstring(p, sep=' ').reshape(48, 48, 1) for p in df['pixels']]) / 255.0\n",
    "y = df['emotion'].values\n",
    "\n",
    "# TEKNIK FOKUS: Menyeimbangkan bobot sekaligus memberi \"Booster\" pada Senang & Terkejut\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# --- MODIFIKASI MANUAL UNTUK FOKUS ---\n",
    "class_weights_dict[3] = class_weights_dict[3] * 2.5  # Booster Senang (Happy)\n",
    "class_weights_dict[5] = class_weights_dict[5] * 2.0  # Booster Terkejut (Surprise)\n",
    "class_weights_dict[4] = class_weights_dict[4] * 1.5  # Sedikit Booster Sedih (Sad)\n",
    "class_weights_dict[6] = class_weights_dict[6] * 1.0  # Netral (Standard)\n",
    "\n",
    "print(\"Bobot emosi telah dimodifikasi.\")\n",
    "\n",
    "# 3. Arsitektur Model (Ultra-Deep ANN)\n",
    "print(\"\\n--- Tahap 3: Membangun Otak Buatan (Deep Architecture) ---\")\n",
    "model = Sequential([\n",
    "    Input(shape=(48, 48, 1)),\n",
    "    Flatten(), \n",
    "    \n",
    "    # Layer 1: Menangkap pola dasar piksel\n",
    "    Dense(2048, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    # Layer 2: Fokus pada fitur wajah\n",
    "    Dense(1024, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Layer 3: Klasifikasi Emosi\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Layer 4: Fine-tuning detail\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # Output Layer: 7 Emosi\n",
    "    Dense(7, activation='softmax') \n",
    "])\n",
    "\n",
    "# Menggunakan Adam dengan learning rate yang dinamis\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"Arsitektur JST Berhasil dibentuk.\")\n",
    "model.summary()\n",
    "\n",
    "# 4. Proses Training\n",
    "print(\"\\n--- Tahap 4: Proses Belajar (Deep Learning) ---\")\n",
    "\n",
    "# Early Stopping: Memantau val_accuracy agar tidak berhenti terlalu cepat\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=25, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ReduceLR: Jika mentok, perkecil langkah belajar agar lebih teliti\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=7, \n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X, y, \n",
    "    epochs=150, \n",
    "    batch_size=64, # Batch size diperkecil agar belajar lebih detail per gambar\n",
    "    validation_split=0.2, \n",
    "    class_weight=class_weights_dict, \n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 5. Simpan Hasil Belajar\n",
    "model.save('model_cerdas.keras')\n",
    "\n",
    "# 6. Ringkasan Hasil\n",
    "final_acc = history.history['accuracy'][-1] * 100\n",
    "final_val_acc = history.history['val_accuracy'][-1] * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"RINGKASAN HASIL TRAINING\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Akurasi Latihan   : {final_acc:.2f}%\")\n",
    "print(f\"Akurasi Validasi  : {final_val_acc:.2f}%\")\n",
    "print(\"-\"*40)\n",
    "print(\"HASIL ANALISIS:\")\n",
    "if final_val_acc > 40:\n",
    "    print(\"SISTEM BERHASIL.\")\n",
    "else:\n",
    "    print(\"Sistem masih butuh waktu belajar lebih lama.\")\n",
    "print(\"=\"*40)\n",
    "print(\"[SUKSES] Model final disimpan sebagai 'model_cerdas.keras'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tahap Akhir: Menyalakan Mata Sistem (Kamera) ---\n",
      "[BERHASIL] Memuat model: model_cerdas.keras\n",
      "SISTEM AKTIF. Tekan 'q' untuk berhenti.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import deque\n",
    "\n",
    "# 1. Konfigurasi Awal\n",
    "model_path = 'model_cerdas.keras'\n",
    "label_emosi = ['Marah', 'Jijik', 'Takut', 'Senang', 'Sedih', 'Terkejut', 'Netral']\n",
    "\n",
    "# Warna khusus untuk setiap emosi (BGR Format)\n",
    "colors = {\n",
    "    'Marah': (0, 0, 255),      # Merah\n",
    "    'Jijik': (0, 255, 128),    # Hijau Muda\n",
    "    'Takut': (255, 0, 255),    # Ungu\n",
    "    'Senang': (0, 255, 255),   # Kuning\n",
    "    'Sedih': (255, 0, 0),      # Biru\n",
    "    'Terkejut': (255, 255, 0), # Cyan\n",
    "    'Netral': (200, 200, 200)  # Abu-abu\n",
    "}\n",
    "\n",
    "# FITUR STABILISATOR: Menyimpan history agar transisi emosi halus (Anti-Loncat)\n",
    "history_size = 20\n",
    "prediksi_history = deque(maxlen=history_size)\n",
    "\n",
    "# Inisialisasi CLAHE agar hasil kamera sinkron dengan preprocessing di Cell 1 & 2\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "print(\"--- Tahap Akhir: Menyalakan Mata Sistem (Kamera) ---\")\n",
    "\n",
    "# 2. Muat Otak Sistem (Model)\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    print(f\"[BERHASIL] Memuat model: {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Model gagal dimuat: {e}\")\n",
    "\n",
    "# 3. Muat Detektor Wajah (Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 4. Inisialisasi Kamera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"[ERROR] Kamera tidak dapat diakses!\")\n",
    "else:\n",
    "    print(\"SISTEM AKTIF. Tekan 'q' untuk berhenti.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    frame = cv2.flip(frame, 1) # Efek cermin\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Deteksi Wajah dalam frame\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # A. PREPROCESSING (Wajib sama dengan Cell 1 & 2)\n",
    "        roi_gray = gray_frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Menerapkan CLAHE (Adaptive Histogram Equalization)\n",
    "        roi_clahe = clahe.apply(roi_gray)\n",
    "        \n",
    "        # Resize ke 48x48 sesuai input model ANN\n",
    "        roi_resized = cv2.resize(roi_clahe, (48, 48))\n",
    "        roi_normalized = roi_resized / 255.0\n",
    "        roi_reshaped = np.reshape(roi_normalized, (1, 48, 48, 1))\n",
    "        \n",
    "        # B. PREDIKSI MENTAH\n",
    "        raw_prediction = model.predict(roi_reshaped, verbose=0)[0]\n",
    "        \n",
    "        # C. PROSES SMOOTHING (Menghitung rata-rata prediksi terakhir)\n",
    "        prediksi_history.append(raw_prediction)\n",
    "        smoothed_prediction = np.mean(prediksi_history, axis=0)\n",
    "        \n",
    "        max_index = np.argmax(smoothed_prediction)\n",
    "        hasil_prediksi = label_emosi[max_index]\n",
    "        akurasi = smoothed_prediction[max_index] * 100\n",
    "        \n",
    "        # Ambil warna sesuai label emosi\n",
    "        color = colors.get(hasil_prediksi, (0, 255, 0))\n",
    "\n",
    "        # D. TAMPILAN HUD (CYBERPUNK STYLE)\n",
    "        # 1. Gambar Sudut Kotak (Corner Borders)\n",
    "        length = int(w * 0.2)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 1) # Garis tipis kotak luar\n",
    "        \n",
    "        # Sudut Kiri Atas\n",
    "        cv2.line(frame, (x, y), (x+length, y), color, 4)\n",
    "        cv2.line(frame, (x, y), (x, y+length), color, 4)\n",
    "        # Sudut Kanan Atas\n",
    "        cv2.line(frame, (x+w, y), (x+w-length, y), color, 4)\n",
    "        cv2.line(frame, (x+w, y), (x+w, y+length), color, 4)\n",
    "        # Sudut Kiri Bawah\n",
    "        cv2.line(frame, (x, y+h), (x+length, y+h), color, 4)\n",
    "        cv2.line(frame, (x, y+h), (x, y+h-length), color, 4)\n",
    "        # Sudut Kanan Bawah\n",
    "        cv2.line(frame, (x+w, y+h), (x+w-length, y+h), color, 4)\n",
    "        cv2.line(frame, (x+w, y+h), (x+w, y+h-length), color, 4)\n",
    "        \n",
    "        # 2. Label Banner Atas (Latar belakang teks)\n",
    "        cv2.rectangle(frame, (x, y-40), (x+w, y), color, -1)\n",
    "        teks = f\"{hasil_prediksi.upper()} {akurasi:.1f}%\"\n",
    "        cv2.putText(frame, teks, (x + 5, y - 10), \n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 0.7, (255, 255, 255), 1)\n",
    "\n",
    "    # UI Informasi Header di pojok kiri atas\n",
    "    cv2.putText(frame, \"AI EMOTION ENGINE\", (20, 40), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, \"PRESS 'Q' TO SHUTDOWN\", (20, 65), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "    # Tampilkan jendela output\n",
    "    cv2.imshow('Sistem Cerdas Emotion Detection', frame)\n",
    "\n",
    "    # Berhenti jika tombol 'q' ditekan\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Bersihkan resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"--- Sistem Dimatikan: Kamera telah dilepaskan ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
